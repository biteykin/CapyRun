# app.py ‚Äî CapyRun FIT Analyzer v3.1 (date merge fix)

import io
import math
import numpy as np
import pandas as pd
import altair as alt
import streamlit as st
from fitparse import FitFile
from datetime import timedelta
from math import exp

# ---------------- UI / Sidebar ----------------
st.set_page_config(page_title="CapyRun ‚Äî FIT Analyzer v3.1", page_icon="üèÉ", layout="wide")
st.title("üèÉ CapyRun ‚Äî FIT Analyzer v3.1")
st.caption("–ó–∞–≥—Ä—É–∑–∏ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ .fit ‚Üí –æ—Ç—á—ë—Ç –ø–æ —Å–µ—Å—Å–∏–∏ / —Ç—Ä–µ–Ω–¥—ã –Ω–∞–≥—Ä—É–∑–∫–∏ / —á–µ—Ä–Ω–æ–≤–∏–∫ –ø–ª–∞–Ω–∞ + Excel")

with st.sidebar:
    st.header("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
    hr_rest = st.number_input("–ü—É–ª—å—Å –≤ –ø–æ–∫–æ–µ (HRrest)", min_value=30, max_value=100, value=60, step=1)
    hr_max  = st.number_input("–ú–∞–∫—Å. –ø—É–ª—å—Å (HRmax)", min_value=140, max_value=220, value=190, step=1)
    zone_bounds = st.text_input("–ì—Ä–∞–Ω–∏—Ü—ã –∑–æ–Ω HR (—É–¥/–º–∏–Ω, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", value="120,140,155,170,185")
    st.caption("–ü—Ä–∏–º–µ—Ä: 120,140,155,170,185 ‚Üí –ø–æ–ª—É—á–∏—Ç—Å—è Z1‚Ä¶Z5")

uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ FIT-—Ñ–∞–π–ª(—ã)", type=["fit"], accept_multiple_files=True)

# ---------------- Helpers ----------------
def get_val(msg, name, alt_name=None):
    v = msg.get_value(name)
    if (v is None) and alt_name:
        v = msg.get_value(alt_name)
    return v

def pace_from_speed(spd):
    if spd is None or spd <= 0: return None
    sec_per_km = 1000.0 / spd
    m = int(sec_per_km // 60); s = int(round(sec_per_km % 60))
    return f"{m}:{s:02d}"

def speed_to_pace_min_per_km(spd):
    if spd is None or spd <= 0: return np.nan
    return (1000.0 / spd) / 60.0

def parse_bounds(text):
    try:
        b = [int(x.strip()) for x in text.split(",") if x.strip()]
        b = [v for v in b if 30 <= v <= 240]
        b.sort()
        return b
    except Exception:
        return []

def compute_trimp_timeweighted(hr, dt, hr_rest, hr_max):
    """TRIMP ‚âà —Å—É–º–º–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–≤ –º–∏–Ω—É—Ç–∞—Ö)."""
    if hr is None or dt is None or hr.isna().all() or dt.isna().all(): return None
    rel = (hr - hr_rest) / max(1, (hr_max - hr_rest))
    rel = rel.clip(lower=0)
    minutes = dt.fillna(0) / 60.0
    val = float((rel * minutes).sum() * 100.0)
    return val if val > 0 else None

def efficiency_factor(speed, hr):
    if speed is None or hr is None: return None
    valid = speed.notna() & hr.notna() & (hr > 0)
    if not valid.any(): return None
    return float(speed[valid].mean() / hr[valid].mean())

def decoupling(speed, hr):
    valid = speed.notna() & hr.notna() & (hr > 0)
    idx = np.where(valid)[0]
    if len(idx) < 40: return None
    half = len(idx) // 2
    first = idx[:half]; second = idx[half:]
    if len(first) < 20 or len(second) < 20: return None
    ef1 = speed.iloc[first].mean() / hr.iloc[first].mean()
    ef2 = speed.iloc[second].mean() / hr.iloc[second].mean()
    if ef1 <= 0: return None
    return float((ef2/ef1 - 1.0) * 100.0)

def zones_time(series, bounds):
    if series is None or series.isna().all() or not bounds: return None
    bins = [-np.inf] + bounds + [np.inf]
    z = pd.cut(series, bins=bins, labels=[f"Z{i}" for i in range(1, len(bins))])
    return z.value_counts().sort_index()

def to_excel(dfs_named: dict):
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="xlsxwriter", datetime_format="yyyy-mm-dd hh:mm:ss") as writer:
        for name, df in dfs_named.items():
            df.to_excel(writer, sheet_name=name, index=False)
            ws = writer.sheets[name]
            if not df.empty:
                ws.autofilter(0, 0, len(df), max(0, len(df.columns)-1))
            ws.freeze_panes(1, 0)
            for i, col in enumerate(df.columns):
                maxlen = min(60, max(len(str(col)), *(len(str(x)) for x in df[col].head(200).fillna("").astype(str))))
                ws.set_column(i, i, max(9, maxlen + 1))
    bio.seek(0)
    return bio

# ---------------- Parsing for one file ----------------
def parse_fit_file(uploaded_file):
    fit = FitFile(uploaded_file)

    # Records
    rec_rows = []
    for m in fit.get_messages("record"):
        rec_rows.append({
            "timestamp": get_val(m, "timestamp"),
            "hr":        get_val(m, "heart_rate"),
            "speed":     get_val(m, "speed", "enhanced_speed"),      # m/s
            "cadence":   get_val(m, "cadence"),
            "power":     get_val(m, "power"),
            "elev":      get_val(m, "altitude", "enhanced_altitude"),
            "dist":      get_val(m, "distance"),                     # meters (cumulative)
        })
    df_rec = pd.DataFrame(rec_rows)
    if not df_rec.empty:
        df_rec["timestamp"] = pd.to_datetime(df_rec["timestamp"], errors="coerce")
        df_rec = df_rec.sort_values("timestamp").reset_index(drop=True)
        if df_rec["timestamp"].notna().any():
            t0 = df_rec["timestamp"].min()
            df_rec["t_rel_s"] = (df_rec["timestamp"] - t0).dt.total_seconds()
        else:
            df_rec["t_rel_s"] = np.arange(len(df_rec))
        df_rec["dt_s"] = df_rec["t_rel_s"].diff().fillna(0).clip(lower=0)  # –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏
        df_rec["pace"] = df_rec["speed"].apply(pace_from_speed)

    # Laps
    lap_rows = []
    for m in fit.get_messages("lap"):
        lap_rows.append({
            "start_time": get_val(m, "start_time"),
            "total_distance_m": get_val(m, "total_distance"),
            "total_timer_time_s": get_val(m, "total_timer_time"),
            "avg_hr": get_val(m, "avg_heart_rate"),
            "max_hr": get_val(m, "max_heart_rate"),
            "avg_speed_m_s": get_val(m, "avg_speed", "enhanced_avg_speed"),
            "max_speed_m_s": get_val(m, "max_speed", "enhanced_max_speed"),
            "avg_cadence": get_val(m, "avg_cadence"),
            "total_ascent_m": get_val(m, "total_ascent"),
            "total_descent_m": get_val(m, "total_descent"),
            "lap_trigger": get_val(m, "lap_trigger"),
        })
    df_laps = pd.DataFrame(lap_rows)
    if not df_laps.empty:
        df_laps["start_time"] = pd.to_datetime(df_laps["start_time"], errors="coerce")
        df_laps = df_laps.sort_values("start_time").reset_index(drop=True)

    # Sessions
    ses_rows = []
    for m in fit.get_messages("session"):
        ses_rows.append({
            "start_time": get_val(m, "start_time"),
            "sport": get_val(m, "sport"),
            "sub_sport": get_val(m, "sub_sport"),
            "total_distance_m": get_val(m, "total_distance"),
            "total_elapsed_time_s": get_val(m, "total_elapsed_time"),
            "total_timer_time_s": get_val(m, "total_timer_time"),
            "avg_hr": get_val(m, "avg_heart_rate"),
            "max_hr": get_val(m, "max_heart_rate"),
            "avg_speed_m_s": get_val(m, "avg_speed", "enhanced_avg_speed"),
            "max_speed_m_s": get_val(m, "max_speed", "enhanced_max_speed"),
            "avg_cadence": get_val(m, "avg_cadence"),
            "total_ascent_m": get_val(m, "total_ascent"),
            "total_descent_m": get_val(m, "total_descent"),
        })
    df_ses = pd.DataFrame(ses_rows)

    # Summary per workout
    start_time = None
    if not df_ses.empty and pd.notna(df_ses.iloc[0].get("start_time")):
        start_time = pd.to_datetime(df_ses.iloc[0]["start_time"])
    elif not df_rec.empty and df_rec["timestamp"].notna().any():
        start_time = df_rec["timestamp"].min()

    # distance
    if not df_ses.empty and pd.notna(df_ses.iloc[0].get("total_distance_m")):
        distance_km = df_ses.iloc[0]["total_distance_m"] / 1000.0
    elif not df_rec.empty and df_rec["dist"].notna().any():
        distance_km = df_rec["dist"].max() / 1000.0
    else:
        distance_km = None

    # time
    if not df_ses.empty and pd.notna(df_ses.iloc[0].get("total_timer_time_s")):
        time_min = df_ses.iloc[0]["total_timer_time_s"] / 60.0
    elif not df_rec.empty and df_rec["t_rel_s"].notna().any():
        time_min = (df_rec["t_rel_s"].max() - df_rec["t_rel_s"].min()) / 60.0
    else:
        time_min = None

    # avg hr
    avg_hr = None
    if not df_ses.empty and pd.notna(df_ses.iloc[0].get("avg_hr")):
        avg_hr = float(df_ses.iloc[0]["avg_hr"])
    elif not df_rec.empty and df_rec["hr"].notna().any():
        avg_hr = float(df_rec["hr"].mean())

    # TRIMP (–≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
    trimp = compute_trimp_timeweighted(
        df_rec["hr"] if "hr" in df_rec else None,
        df_rec["dt_s"] if "dt_s" in df_rec else None,
        hr_rest, hr_max
    )

    # EF / Decoupling
    ef = efficiency_factor(df_rec["speed"] if "speed" in df_rec else None,
                           df_rec["hr"] if "hr" in df_rec else None)
    de = decoupling(df_rec["speed"] if "speed" in df_rec else None,
                    df_rec["hr"] if "hr" in df_rec else None)

    summary = {
        "start_time": start_time,
        "date": start_time.date() if start_time else None,  # –±—É–¥–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ –ø–æ–∑–∂–µ
        "sport": (df_ses.iloc[0]["sport"] if not df_ses.empty else None),
        "distance_km": round(distance_km, 2) if distance_km else None,
        "time_min": round(time_min, 1) if time_min else None,
        "avg_hr": round(avg_hr) if avg_hr else None,
        "TRIMP": round(trimp) if trimp else None,
        "EF": round(ef, 4) if ef else None,
        "Pa:Hr_%": round(de, 1) if de is not None else None,
    }

    return df_rec, df_laps, df_ses, summary

# ---------------- Main logic ----------------
if not uploaded:
    st.info("–ó–∞–≥—Ä—É–∑–∏ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ .fit —Ñ–∞–π–ª–æ–≤, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –æ—Ç—á—ë—Ç/–ø—Ä–æ–≥—Ä–µ—Å—Å.")
else:
    # –û–¥–∏–Ω —Ñ–∞–π–ª ‚Üí –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
    if len(uploaded) == 1:
        file = uploaded[0]
        df_rec, df_laps, df_ses, summary = parse_fit_file(file)

        bounds = parse_bounds(zone_bounds)
        zt = zones_time(df_rec["hr"], bounds) if (not df_rec.empty and bounds) else None

        # Summary metrics
        c1,c2,c3 = st.columns(3)
        with c1: st.metric("–î–∏—Å—Ç–∞–Ω—Ü–∏—è", f"{summary['distance_km']:.2f} –∫–º" if summary["distance_km"] else "‚Äî")
        with c2: st.metric("–í—Ä–µ–º—è", f"{summary['time_min']:.1f} –º–∏–Ω" if summary["time_min"] else "‚Äî")
        with c3: st.metric("TRIMP (‚âà)", f"{summary['TRIMP']}" if summary["TRIMP"] else "‚Äî")

        c4,c5,c6 = st.columns(3)
        with c4: st.metric("EF (—Å–∫–æ—Ä–æ—Å—Ç—å/HR)", f"{summary['EF']}" if summary["EF"] else "‚Äî")
        with c5: st.metric("Decoupling Pa:Hr", f"{summary['Pa:Hr_%']}%" if summary["Pa:Hr_%"] is not None else "‚Äî")
        with c6: st.metric("–°—Ä–µ–¥–Ω–∏–π HR", f"{summary['avg_hr']}" if summary["avg_hr"] else "‚Äî")

        st.divider()

        # Charts
        if not df_rec.empty:
            left, right = st.columns(2)
            with left:
                st.subheader("–ü—É–ª—å—Å –∏ —Ç–µ–º–ø")
                base = pd.DataFrame({
                    "t_min": df_rec["t_rel_s"] / 60.0,
                    "HR": df_rec["hr"],
                    "Pace (–º–∏–Ω/–∫–º)": pd.to_numeric(df_rec["speed"].apply(speed_to_pace_min_per_km), errors="coerce")
                })
                st.altair_chart(alt.Chart(base).mark_line().encode(x="t_min:Q", y="HR:Q").interactive(), use_container_width=True)
                st.altair_chart(alt.Chart(base).mark_line().encode(x="t_min:Q", y=alt.Y("Pace (–º–∏–Ω/–∫–º):Q", sort="descending")).interactive(), use_container_width=True)
            with right:
                st.subheader("–ö–∞–¥–µ–Ω—Å –∏ –≤—ã—Å–æ—Ç–∞")
                base2 = pd.DataFrame({
                    "t_min": df_rec["t_rel_s"] / 60.0,
                    "Cadence (spm)": df_rec["cadence"],
                    "Elevation (m)": df_rec["elev"],
                })
                st.altair_chart(alt.Chart(base2).mark_line().encode(x="t_min:Q", y="Cadence (spm):Q").interactive(), use_container_width=True)
                st.altair_chart(alt.Chart(base2).mark_line().encode(x="t_min:Q", y="Elevation (m):Q").interactive(), use_container_width=True)

        # Zones
        st.subheader("–ó–æ–Ω—ã –ø—É–ª—å—Å–∞")
        if zt is not None:
            df_z = zt.rename_axis("Zone").reset_index(name="seconds")
            total = df_z["seconds"].sum()
            df_z["%"] = (df_z["seconds"] / total * 100).round(1)
            st.dataframe(df_z)
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö HR –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã –≥—Ä–∞–Ω–∏—Ü—ã –∑–æ–Ω.")

        # Tables
        st.subheader("–°–µ—Å—Å–∏—è")
        st.dataframe(df_ses if not df_ses.empty else pd.DataFrame(columns=["‚Äî"]))
        st.subheader("–ö—Ä—É–≥–∏ (laps)")
        st.dataframe(df_laps if not df_laps.empty else pd.DataFrame(columns=["‚Äî"]))
        st.subheader("–¢–æ—á–∫–∏ (records) ‚Äî –±–µ–∑ GPS")
        st.dataframe(df_rec.head(500) if not df_rec.empty else pd.DataFrame(columns=["‚Äî"]))
        if not df_rec.empty and len(df_rec) > 500:
            st.caption(f"–ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 500 —Å—Ç—Ä–æ–∫ –∏–∑ {len(df_rec)}.")

        # Download
        xls = to_excel({
            "Summary": pd.DataFrame([summary]),
            "Sessions": df_ses,
            "Laps": df_laps,
            "Records": df_rec
        })
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Excel", data=xls,
                           file_name="fit_report.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ ‚Üí –¥–∞—à–±–æ—Ä–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    else:
        st.subheader("üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: —Å–≤–æ–¥–∫–∞ –ø–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞–º")
        summaries = []
        for f in uploaded:
            df_rec, df_laps, df_ses, summary = parse_fit_file(f)
            summaries.append(summary)

        df_sum = pd.DataFrame(summaries).dropna(subset=["date"]).sort_values("start_time").reset_index(drop=True)

        # --- FIX: –ø—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø –∫–ª—é—á–∞ –∫ datetime64[ns] (–ø–æ–ª–Ω–æ—á—å) ---
        if not df_sum.empty:
            df_sum["date"] = pd.to_datetime(df_sum["date"]).dt.normalize()

        st.dataframe(df_sum)

        # ---- –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –∏ ATL/CTL/TSB ----
        st.subheader("–ù–∞–≥—Ä—É–∑–∫–∞ (TRIMP) –ø–æ –¥–Ω—è–º –∏ —Ç—Ä–µ–Ω–¥—ã ATL/CTL/TSB")

        if df_sum.empty:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö —Å –¥–∞—Ç–∞–º–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤.")
            st.stop()

        daily = df_sum.groupby("date").agg(
            TRIMP=("TRIMP", "sum"),
            distance_km=("distance_km", "sum")
        ).reset_index()

        # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ min..max –ø–æ df_sum
        full = pd.DataFrame({
            "date": pd.date_range(df_sum["date"].min(), df_sum["date"].max(), freq="D")
        })
        daily = full.merge(daily, on="date", how="left").fillna({"TRIMP": 0.0, "distance_km": 0.0})

        # EWMA –≤—Ä—É—á–Ω—É—é (–µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π —à–∞–≥)
        def ewma(load, tau_days):
            alpha = 1 - exp(-1.0 / tau_days)
            out = []
            prev = 0.0
            for v in load:
                prev = prev + alpha * (v - prev)
                out.append(prev)
            return np.array(out)

        daily["ATL"] = ewma(daily["TRIMP"].values, tau_days=7)
        daily["CTL"] = ewma(daily["TRIMP"].values, tau_days=42)
        daily["TSB"] = daily["CTL"] - daily["ATL"]

        # –≥—Ä–∞—Ñ–∏–∫
        base = daily.melt(id_vars="date", value_vars=["TRIMP","ATL","CTL","TSB"], var_name="metric", value_name="value")
        chart = alt.Chart(base).mark_line().encode(
            x="date:T",
            y="value:Q",
            color="metric:N"
        ).interactive()
        st.altair_chart(chart, use_container_width=True)

        # quick KPIs –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
        last7 = daily.tail(7)
        c1,c2,c3,c4 = st.columns(4)
        with c1: st.metric("TRIMP 7–¥", f"{last7['TRIMP'].sum():.0f}")
        with c2: st.metric("DIST 7–¥", f"{last7['distance_km'].sum():.1f} –∫–º")
        with c3: st.metric("ATL (—Å–µ–≥–æ–¥–Ω—è)", f"{daily['ATL'].iloc[-1]:.0f}")
        with c4: st.metric("TSB (—Å–µ–≥–æ–¥–Ω—è)", f"{daily['TSB'].iloc[-1]:.0f}")

        # ---- –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–ª–∞–Ω–∞ –Ω–∞ 7 –¥–Ω–µ–π ----
        st.subheader("üìù –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–ª–∞–Ω–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–¥–µ–ª—é")
        last_week_km = float(last7["distance_km"].sum())
        tsb = float(daily["TSB"].iloc[-1])

        # –ª–æ–≥–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–±—ä—ë–º–∞
        if tsb < -10:
            target_km = max(0.0, last_week_km * 0.9)  # –ª—ë–≥–∫–∏–π –¥–∏–ª–æ–∞–¥
            note = "TSB –Ω–∏–∑–∫–∏–π ‚Üí —Å–Ω–∏–∑–∏–º –æ–±—ä—ë–º (~-10%) –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è."
        elif tsb > 10:
            target_km = last_week_km * 1.10  # –Ω–µ–±–æ–ª—å—à–æ–π —Ä–æ—Å—Ç
            note = "TSB –≤—ã—Å–æ–∫–∏–π ‚Üí –º–æ–∂–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–æ–¥–Ω—è—Ç—å –æ–±—ä—ë–º (~+10%)."
        else:
            target_km = last_week_km * 1.05  # –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ/—Å–ª–µ–≥–∫–∞ –≤–≤–µ—Ä—Ö
            note = "TSB –≤ –Ω–æ—Ä–º–µ ‚Üí –ø–æ–¥–¥–µ—Ä–∂–∏–º/—Å–ªightly —É–≤–µ–ª–∏—á–∏–º (~+5%)."

        # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä—ë–º–∞ (–∫–º) –ø–æ –¥–Ω—è–º (–ø—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ö–µ–º–∞)
        dist_split = np.array([0.12,0.16,0.10,0.18,0.08,0.26,0.10])  # –ü–Ω..–í—Å
        day_names = ["–ü–Ω","–í—Ç","–°—Ä","–ß—Ç","–ü—Ç","–°–±","–í—Å"]
        km_plan = (dist_split * target_km).round(1)

        # —Ç–∏–ø—ã —Å–µ—Å—Å–∏–π
        types = ["Easy Z1‚ÄìZ2", "Tempo Z3 (20‚Äì30 –º–∏–Ω)", "Easy Z1‚ÄìZ2",
                 "Intervals Z4 (6√ó3‚Äô/2‚Äô)", "Recovery 30‚Äì40‚Äô Z1", "Long Z2", "Easy + strides"]

        plan_df = pd.DataFrame({
            "–î–µ–Ω—å": day_names,
            "–¢–∏–ø": types,
            "–ü—Ä–æ–±–µ–∂–∫–∞ (–∫–º)": km_plan
        })

        st.write(note)
        st.dataframe(plan_df)

        st.write(note)
st.dataframe(plan_df)


# ---- –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–ª–∞–Ω–∞ –Ω–∞ 7 –¥–Ω–µ–π ----
st.subheader("üìù –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–ª–∞–Ω–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–¥–µ–ª—é")

plan_df = pd.DataFrame()   # <-- –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
note = None

# –≥–æ—Ç–æ–≤–∏–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
last7 = daily.tail(7) if not daily.empty else pd.DataFrame()

if not daily.empty and not last7.empty:
    last_week_km = float(last7["distance_km"].sum())
    tsb = float(daily["TSB"].iloc[-1])

    # –ª–æ–≥–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–±—ä—ë–º–∞
    if tsb < -10:
        target_km = max(0.0, last_week_km * 0.9)   # –ª—ë–≥–∫–∏–π –¥–∏–ª–æ–∞–¥
        note = "TSB –Ω–∏–∑–∫–∏–π ‚Üí —Å–Ω–∏–∑–∏–º –æ–±—ä—ë–º (~-10%) –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è."
    elif tsb > 10:
        target_km = last_week_km * 1.10            # –Ω–µ–±–æ–ª—å—à–æ–π —Ä–æ—Å—Ç
        note = "TSB –≤—ã—Å–æ–∫–∏–π ‚Üí –º–æ–∂–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–æ–¥–Ω—è—Ç—å –æ–±—ä—ë–º (~+10%)."
    else:
        target_km = last_week_km * 1.05            # –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ/—Å–ª–µ–≥–∫–∞ –≤–≤–µ—Ä—Ö
        note = "TSB –≤ –Ω–æ—Ä–º–µ ‚Üí –ø–æ–¥–¥–µ—Ä–∂–∏–º/—Å–ª–µ–≥–∫–∞ —É–≤–µ–ª–∏—á–∏–º (~+5%)."

    # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä—ë–º–∞ (–∫–º) –ø–æ –¥–Ω—è–º (–ø—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ö–µ–º–∞)
    dist_split = np.array([0.12,0.16,0.10,0.18,0.08,0.26,0.10])  # –ü–Ω..–í—Å
    day_names = ["–ü–Ω","–í—Ç","–°—Ä","–ß—Ç","–ü—Ç","–°–±","–í—Å"]
    km_plan = (dist_split * target_km).round(1)

    # —Ç–∏–ø—ã —Å–µ—Å—Å–∏–π
    types = ["Easy Z1‚ÄìZ2", "Tempo Z3 (20‚Äì30 –º–∏–Ω)", "Easy Z1‚ÄìZ2",
             "Intervals Z4 (6√ó3‚Äô/2‚Äô)", "Recovery 30‚Äì40‚Äô Z1", "Long Z2", "Easy + strides"]

    plan_df = pd.DataFrame({
        "–î–µ–Ω—å": day_names,
        "–¢–∏–ø": types,
        "–ü—Ä–æ–±–µ–∂–∫–∞ (–∫–º)": km_plan
    })

    if note:
        st.write(note)
    st.dataframe(plan_df)
else:
    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–ª–∞–Ω–∞ (–Ω—É–∂–Ω–æ ‚â•1 –¥–µ–Ω—å —Å –¥–∞–Ω–Ω—ã–º–∏).")

# === NEW: –≠–∫—Å–ø–æ—Ä—Ç –ø–ª–∞–Ω–∞ –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å (ICS) ===
import datetime as dt  # –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ —Å–∞–º—ã–π –≤–µ—Ä—Ö —Ñ–∞–π–ª–∞

with st.expander("üìÜ –≠–∫—Å–ø–æ—Ä—Ç –ø–ª–∞–Ω–∞ –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å (.ics)"):
    if plan_df.empty:
        st.warning("–ü–ª–∞–Ω –ø—É—Å—Ç ‚Äî —Å–Ω–∞—á–∞–ª–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π –µ–≥–æ –≤—ã—à–µ.")
    else:
        # –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
        today = dt.date.today()
        next_monday = today + dt.timedelta(days=(7 - today.weekday())) if today.weekday() != 0 else today

        start_date = st.date_input("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–ª–∞–Ω–∞", value=next_monday, help="–° –∫–∞–∫–æ–≥–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ")
        workout_time = st.time_input("–í—Ä–µ–º—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏", value=dt.time(7, 0))
        selected_days = st.multiselect(
            "–ö–∞–∫–∏–µ –¥–Ω–∏ –¥–æ–±–∞–≤–∏—Ç—å",
            options=["–ü–Ω","–í—Ç","–°—Ä","–ß—Ç","–ü—Ç","–°–±","–í—Å"],
            default=["–ü–Ω","–í—Ç","–°—Ä","–ß—Ç","–ü—Ç","–°–±","–í—Å"]
        )
        duration_minutes = st.number_input("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–µ (–º–∏–Ω)", min_value=15, max_value=240, value=60, step=5)

        # –º–∞–ø–ø–∏–Ω–≥ –¥–Ω–µ–π
        day_to_idx = {"–ü–Ω":0,"–í—Ç":1,"–°—Ä":2,"–ß—Ç":3,"–ü—Ç":4,"–°–±":5,"–í—Å":6}

        def dtstamp():
            return dt.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")

        def fmt_dt(d: dt.date, t: dt.time):
            return dt.datetime.combine(d, t).strftime("%Y%m%dT%H%M%S")

        def build_ics(plan_df, start_date, workout_time, selected_days, duration_minutes):
            lines = [
                "BEGIN:VCALENDAR",
                "VERSION:2.0",
                "PRODID:-//CapyRun//Weekly Plan//EN"
            ]
            for _, row in plan_df.iterrows():
                day = str(row["–î–µ–Ω—å"])
                if day not in selected_days:
                    continue
                idx = day_to_idx.get(day, 0)
                d = start_date + dt.timedelta(days=idx)
                start = fmt_dt(d, workout_time)
                end_dt = (dt.datetime.combine(d, workout_time) + dt.timedelta(minutes=int(duration_minutes)))
                end = end_dt.strftime("%Y%m%dT%H%M%S")

                title = f'{row["–¢–∏–ø"]} ‚Äî {row["–ü—Ä–æ–±–µ–∂–∫–∞ (–∫–º)"]} –∫–º'
                desc = f'CapyRun: {row["–¢–∏–ø"]}. –ü–ª–∞–Ω–æ–≤—ã–π –æ–±—ä—ë–º: {row["–ü—Ä–æ–±–µ–∂–∫–∞ (–∫–º)"]} –∫–º.'

                uid = f"{start}-{hash(title) & 0xffffffff}@capyrun"
                lines += [
                    "BEGIN:VEVENT",
                    f"UID:{uid}",
                    f"DTSTAMP:{dtstamp()}",
                    f"DTSTART:{start}",
                    f"DTEND:{end}",
                    f"SUMMARY:{title}",
                    f"DESCRIPTION:{desc}",
                    "END:VEVENT"
                ]
            lines.append("END:VCALENDAR")
            return "\n".join(lines)

        ics_text = build_ics(plan_df, start_date, workout_time, selected_days, duration_minutes)
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å iCal (.ics)",
            data=ics_text,
            file_name="capyrun_plan.ics",
            mime="text/calendar"
        )



# ---- –í—ã–≥—Ä—É–∑–∫–∞ Excel: Progress + Plan ----
xls = to_excel({
    "Workouts": df_sum,
    "DailyLoad": daily,
    "NextWeekPlan": plan_df
})
st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Excel (–ø—Ä–æ–≥—Ä–µ—Å—Å + –ø–ª–∞–Ω)", data=xls,
                   file_name="capyrun_progress.xlsx",
                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
